{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ec5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os \n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "\n",
    "train = pd.read_csv('input/train.csv') # train data link\n",
    "test = pd.read_csv('input/test.csv') # test data link"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0dbcff7",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "### Delete duplicates and Check for unique values in each features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba2f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of duplicates rows : 0, (0.0%)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "failure               2\n",
       "attribute_0           2\n",
       "attribute_1           3\n",
       "attribute_2           4\n",
       "attribute_3           4\n",
       "product_code          5\n",
       "measurement_2        25\n",
       "measurement_0        29\n",
       "measurement_1        30\n",
       "measurement_5      4671\n",
       "measurement_4      4692\n",
       "measurement_6      4704\n",
       "measurement_9      4708\n",
       "measurement_8      4713\n",
       "measurement_3      4721\n",
       "measurement_7      4734\n",
       "measurement_13     5271\n",
       "measurement_10     6177\n",
       "measurement_14     6389\n",
       "measurement_12     6392\n",
       "measurement_11     6526\n",
       "measurement_15     6577\n",
       "measurement_16     7035\n",
       "loading           11950\n",
       "measurement_17    23612\n",
       "id                26570\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scan_dup(df, delete = False):\n",
    "    # Print number of duplicates for each line , duplicates deleted when 'delete' be True.\n",
    "    print(f\"# of duplicates rows : {df.duplicated().sum()}, ({np.round(100*df.duplicated().sum()/len(df),1)}%)\")\n",
    "    if delete :\n",
    "        df.drop_duplicates(inplace = True)\n",
    "\n",
    "def remove_badfeat(df_train, df_test, features):\n",
    "    # Remove categorical features where train&test dataframe have different unique values\n",
    "    for feat in features :\n",
    "        if len(set(df_train[feat].unique()) ^ set(df_test[feat].unique()) )> 0 :\n",
    "            print(f\"Cat-feature {feat} has different values in train & test set \\n\")\n",
    "            print(f\" --> {feat} is deleted \\n\")\n",
    "            print(df_train[feat].unique(), df_test[feat].unique() ,\"\\n\")\n",
    "            del df_train[feat]\n",
    "            del df_test[feat]\n",
    "\n",
    "###########\n",
    "scan_dup(train)\n",
    "print(\"\\n\")\n",
    "train.nunique().sort_values(ascending=True)\n",
    "#print(\"\\n\")\n",
    "#test[\"product_code\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7af8285e",
   "metadata": {},
   "source": [
    "### Check  missing values of each feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d4374ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "product_code         0\n",
       "loading            250\n",
       "attribute_0          0\n",
       "attribute_1          0\n",
       "attribute_2          0\n",
       "attribute_3          0\n",
       "measurement_0        0\n",
       "measurement_1        0\n",
       "measurement_2        0\n",
       "measurement_3      381\n",
       "measurement_4      538\n",
       "measurement_5      676\n",
       "measurement_6      796\n",
       "measurement_7      937\n",
       "measurement_8     1048\n",
       "measurement_9     1227\n",
       "measurement_10    1300\n",
       "measurement_11    1468\n",
       "measurement_12    1601\n",
       "measurement_13    1774\n",
       "measurement_14    1874\n",
       "measurement_15    2009\n",
       "measurement_16    2110\n",
       "measurement_17    2284\n",
       "failure              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89774a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\confi\\AppData\\Local\\Temp\\ipykernel_9168\\3744922203.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  train_gp = train.groupby('product_code').mean().T\n",
      "C:\\Users\\confi\\AppData\\Local\\Temp\\ipykernel_9168\\3744922203.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_gp = test.groupby('product_code').mean().T\n"
     ]
    }
   ],
   "source": [
    "train_gp = train.groupby('product_code').mean().T\n",
    "test_gp = test.groupby('product_code').mean().T\n",
    "\n",
    "data = pd.concat([train_gp,test_gp], axis = 1 ).corr(method = 'kendall')\n",
    "data[data==1] = -1\n",
    "\n",
    "#test['product_code'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7eae40c9",
   "metadata": {},
   "source": [
    "### Features filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81506961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat-feature product_code has different values in train & test set \n",
      "\n",
      " --> product_code is deleted \n",
      "\n",
      "['A' 'B' 'C' 'D' 'E'] ['F' 'G' 'H' 'I'] \n",
      "\n",
      "Cat-feature attribute_1 has different values in train & test set \n",
      "\n",
      " --> attribute_1 is deleted \n",
      "\n",
      "['material_8' 'material_5' 'material_6'] ['material_6' 'material_7' 'material_5'] \n",
      "\n",
      "Cat-feature measurement_0 has different values in train & test set \n",
      "\n",
      " --> measurement_0 is deleted \n",
      "\n",
      "[ 7 14 12 13  9 11  4 10  6  8 21 15 17 18 19 16  5 25  3  1 23 20 22  2\n",
      " 26 24  0 29 27] [ 6 11  8 14 10 16  7 20  9  5  2 13  3  4 15 19 12 22 21 18 17 23  0 26\n",
      " 24  1 25 29 30 28] \n",
      "\n",
      "Cat-feature measurement_1 has different values in train & test set \n",
      "\n",
      " --> measurement_1 is deleted \n",
      "\n",
      "[ 8  3  1  2  4  6  0  9  5  7 10 12 11 13 17 14 16 15 18 20 24 22 21 19\n",
      " 23 27 25 26 29 28] [ 9  8 12 11 16 18  7 15 19 10 13  6 14  5  2  4 17 25 22 21 23  3 20 26\n",
      " 24 31 27 28  1 29 33 32  0] \n",
      "\n",
      "Cat-feature measurement_2 has different values in train & test set \n",
      "\n",
      " --> measurement_2 is deleted \n",
      "\n",
      "[ 4  3  5  6  8  0  7  2 10  9 15 12 11  1 13 16 14 19 17 18 20 21 23 24\n",
      " 22] [ 6  0  4 10  8  7 11  9 18  3 13  5  1 12 21  2 15 22 17 16 14 24 19 23\n",
      " 20 26 28 25] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Those having more than 50 unique values are considered numerical features\n",
    "cat_feat = [feat for feat in train.columns if train[feat].nunique() < 50 and feat!= \"attribute_2\" and feat!=\"attribute_3\" and feat!= 'failure' ]\n",
    "num_feat = [feat for feat in train.columns if feat not in cat_feat and feat!= 'failure']\n",
    "\n",
    "# Remove categorical features where train&test dataframe have different unique values\n",
    "remove_badfeat(train,test,cat_feat)\n",
    "\n",
    "# Train&Test sets both have same unique values in each column , encode the former feature as a binary variable\n",
    "train['attribute_0'] = train['attribute_0'].map({'material_7':0,'material_5':1})\n",
    "test['attribute_0'] = test['attribute_0'].map({'material_7':0,'material_5':1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c564ecb",
   "metadata": {},
   "source": [
    "### Filling missing data and label encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8723be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\confi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train['measurement_avg'] = train[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\n",
    "test['measurement_avg'] = test[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\n",
    "\n",
    "train['m3_missing'] = train['measurement_3'].isnull().astype(np.int8)\n",
    "train['m5_missing'] = train['measurement_5'].isnull().astype(np.int8)\n",
    "\n",
    "test['m3_missing'] = test['measurement_3'].isnull().astype(np.int8)\n",
    "test['m5_missing'] = test['measurement_5'].isnull().astype(np.int8)\n",
    "\n",
    "\n",
    "#measure_gp1_cols = [f\"measurement_{i:d}\" for i in list(range(3, 5)) + list(range(9, 17))]\n",
    "measure_gp2_cols = [f\"measurement_{i:d}\" for i in list(range(5, 9))]\n",
    "train['measure_gp2_avg'] = np.mean(train[measure_gp2_cols], axis=1)\n",
    "test['measure_gp2_avg'] = np.mean(test[measure_gp2_cols], axis=1)\n",
    "\n",
    "train['attribute_2*3'] = train['attribute_2'] * train['attribute_3']\n",
    "test['attribute_2*3'] = test['attribute_2'] * test['attribute_3']\n",
    "\n",
    "#train.head()\n",
    "\n",
    "# One-hot encoding\n",
    "encoded_col = []\n",
    "for col in encoded_col:\n",
    "     tmp_train= pd.get_dummies(test[col], prefix = col)\n",
    "     test = pd.merge(left = test, right = tmp_train, left_index = True, right_index = True)\n",
    "test = test.drop(encoded_col, axis = 1)\n",
    "#test.head()\n",
    "\n",
    "x_train = train[train.columns.difference([\"failure\",'id',\"attribute_2\",\"attribute_3\"])]\n",
    "x_test = test[test.columns.difference(['id', \"attribute_2\",\"attribute_3\"])]\n",
    "y_train = train[\"failure\"]\n",
    "\n",
    "#x_train.head()\n",
    "#x_test.head()\n",
    "iter_imputer = IterativeImputer(max_iter = 8, random_state = 0, skip_complete = True, n_nearest_features = 12)\n",
    "x_train= iter_imputer.fit_transform(x_train)\n",
    "x_test=iter_imputer.transform(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd58ddf0",
   "metadata": {},
   "source": [
    "# Load model & get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb24196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650/650 [==============================] - 0s 503us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# Model download link : https://drive.google.com/file/d/1Jbzr1SQ-iFxKGfbqNFEFfhpfu1-Er1wH/view?usp=share_link\n",
    "# Or run 109550135_Final_train.ipynb first , it'll be in the same directory as this file\n",
    "model = load_model('109550135_model.h5') #   \n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8146e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('input/sample_submission.csv') # sample_submission.csv link\n",
    "submission['failure'] = y_pred\n",
    "submission.to_csv('109550135.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "da82e2444a858c0e6f7823633dc56ff3b236dbe57b9476fd66c4ad2e5bdc4c81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
