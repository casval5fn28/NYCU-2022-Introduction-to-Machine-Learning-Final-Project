{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ec5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os \n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "\n",
    "random_seed = 328#328\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.compat.v1.set_random_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692a2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv') # train data link\n",
    "test = pd.read_csv('input/test.csv') # test data link\n",
    "\n",
    "#train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0dbcff7",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "### Delete duplicates and Check for unique values in each features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba2f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of duplicates rows : 0, (0.0%)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "failure               2\n",
       "attribute_0           2\n",
       "attribute_1           3\n",
       "attribute_2           4\n",
       "attribute_3           4\n",
       "product_code          5\n",
       "measurement_2        25\n",
       "measurement_0        29\n",
       "measurement_1        30\n",
       "measurement_5      4671\n",
       "measurement_4      4692\n",
       "measurement_6      4704\n",
       "measurement_9      4708\n",
       "measurement_8      4713\n",
       "measurement_3      4721\n",
       "measurement_7      4734\n",
       "measurement_13     5271\n",
       "measurement_10     6177\n",
       "measurement_14     6389\n",
       "measurement_12     6392\n",
       "measurement_11     6526\n",
       "measurement_15     6577\n",
       "measurement_16     7035\n",
       "loading           11950\n",
       "measurement_17    23612\n",
       "id                26570\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scan_dup(df, delete = False):\n",
    "    # Print number of duplicates for each line , duplicates deleted when 'delete' be True.\n",
    "    print(f\"# of duplicates rows : {df.duplicated().sum()}, ({np.round(100*df.duplicated().sum()/len(df),1)}%)\")\n",
    "    if delete :\n",
    "        df.drop_duplicates(inplace = True)\n",
    "\n",
    "def remove_badfeat(df_train, df_test, features):\n",
    "    # Remove categorical features where train&test dataframe have different unique values\n",
    "    for feat in features :\n",
    "        if len(set(df_train[feat].unique()) ^ set(df_test[feat].unique()) )> 0 :\n",
    "            print(f\"Cat-feature {feat} has different values in train & test set \\n\")\n",
    "            print(f\" --> {feat} is deleted \\n\")\n",
    "            print(df_train[feat].unique(), df_test[feat].unique() ,\"\\n\")\n",
    "            del df_train[feat]\n",
    "            del df_test[feat]\n",
    "\n",
    "###########\n",
    "scan_dup(train)\n",
    "print(\"\\n\")\n",
    "train.nunique().sort_values(ascending=True)\n",
    "#print(\"\\n\")\n",
    "#test[\"product_code\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7af8285e",
   "metadata": {},
   "source": [
    "### Check  missing values of each feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4374ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "product_code         0\n",
       "loading            250\n",
       "attribute_0          0\n",
       "attribute_1          0\n",
       "attribute_2          0\n",
       "attribute_3          0\n",
       "measurement_0        0\n",
       "measurement_1        0\n",
       "measurement_2        0\n",
       "measurement_3      381\n",
       "measurement_4      538\n",
       "measurement_5      676\n",
       "measurement_6      796\n",
       "measurement_7      937\n",
       "measurement_8     1048\n",
       "measurement_9     1227\n",
       "measurement_10    1300\n",
       "measurement_11    1468\n",
       "measurement_12    1601\n",
       "measurement_13    1774\n",
       "measurement_14    1874\n",
       "measurement_15    2009\n",
       "measurement_16    2110\n",
       "measurement_17    2284\n",
       "failure              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89774a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\confi\\AppData\\Local\\Temp\\ipykernel_2256\\3744922203.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  train_gp = train.groupby('product_code').mean().T\n",
      "C:\\Users\\confi\\AppData\\Local\\Temp\\ipykernel_2256\\3744922203.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_gp = test.groupby('product_code').mean().T\n"
     ]
    }
   ],
   "source": [
    "train_gp = train.groupby('product_code').mean().T\n",
    "test_gp = test.groupby('product_code').mean().T\n",
    "\n",
    "data = pd.concat([train_gp,test_gp], axis = 1 ).corr(method = 'kendall')\n",
    "data[data==1] = -1\n",
    "\n",
    "#test['product_code'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7eae40c9",
   "metadata": {},
   "source": [
    "### Features filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81506961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat-feature product_code has different values in train & test set \n",
      "\n",
      " --> product_code is deleted \n",
      "\n",
      "['A' 'B' 'C' 'D' 'E'] ['F' 'G' 'H' 'I'] \n",
      "\n",
      "Cat-feature attribute_1 has different values in train & test set \n",
      "\n",
      " --> attribute_1 is deleted \n",
      "\n",
      "['material_8' 'material_5' 'material_6'] ['material_6' 'material_7' 'material_5'] \n",
      "\n",
      "Cat-feature measurement_0 has different values in train & test set \n",
      "\n",
      " --> measurement_0 is deleted \n",
      "\n",
      "[ 7 14 12 13  9 11  4 10  6  8 21 15 17 18 19 16  5 25  3  1 23 20 22  2\n",
      " 26 24  0 29 27] [ 6 11  8 14 10 16  7 20  9  5  2 13  3  4 15 19 12 22 21 18 17 23  0 26\n",
      " 24  1 25 29 30 28] \n",
      "\n",
      "Cat-feature measurement_1 has different values in train & test set \n",
      "\n",
      " --> measurement_1 is deleted \n",
      "\n",
      "[ 8  3  1  2  4  6  0  9  5  7 10 12 11 13 17 14 16 15 18 20 24 22 21 19\n",
      " 23 27 25 26 29 28] [ 9  8 12 11 16 18  7 15 19 10 13  6 14  5  2  4 17 25 22 21 23  3 20 26\n",
      " 24 31 27 28  1 29 33 32  0] \n",
      "\n",
      "Cat-feature measurement_2 has different values in train & test set \n",
      "\n",
      " --> measurement_2 is deleted \n",
      "\n",
      "[ 4  3  5  6  8  0  7  2 10  9 15 12 11  1 13 16 14 19 17 18 20 21 23 24\n",
      " 22] [ 6  0  4 10  8  7 11  9 18  3 13  5  1 12 21  2 15 22 17 16 14 24 19 23\n",
      " 20 26 28 25] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Those having more than 50 unique values are considered numerical features\n",
    "cat_feat = [feat for feat in train.columns if train[feat].nunique() < 50 and feat!= \"attribute_2\" and feat!=\"attribute_3\" and feat!= 'failure' ]\n",
    "num_feat = [feat for feat in train.columns if feat not in cat_feat and feat!= 'failure']\n",
    "\n",
    "# Remove categorical features where train&test dataframe have different unique values\n",
    "remove_badfeat(train,test,cat_feat)\n",
    "\n",
    "# Train&Test sets both have same unique values in each column , encode the former feature as a binary variable\n",
    "train['attribute_0'] = train['attribute_0'].map({'material_7':0,'material_5':1})\n",
    "test['attribute_0'] = test['attribute_0'].map({'material_7':0,'material_5':1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c564ecb",
   "metadata": {},
   "source": [
    "### Filling missing data and label encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db8723be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\confi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train['measurement_avg'] = train[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\n",
    "test['measurement_avg'] = test[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\n",
    "\n",
    "train['m3_missing'] = train['measurement_3'].isnull().astype(np.int8)\n",
    "train['m5_missing'] = train['measurement_5'].isnull().astype(np.int8)\n",
    "\n",
    "test['m3_missing'] = test['measurement_3'].isnull().astype(np.int8)\n",
    "test['m5_missing'] = test['measurement_5'].isnull().astype(np.int8)\n",
    "\n",
    "#measure_gp1_cols = [f\"measurement_{i:d}\" for i in list(range(3, 5)) + list(range(9, 17))]\n",
    "measure_gp2_cols = [f\"measurement_{i:d}\" for i in list(range(5, 9))]\n",
    "train['measure_gp2_avg'] = np.mean(train[measure_gp2_cols], axis=1)\n",
    "test['measure_gp2_avg'] = np.mean(test[measure_gp2_cols], axis=1)\n",
    "\n",
    "train['attribute_2*3'] = train['attribute_2'] * train['attribute_3']\n",
    "test['attribute_2*3'] = test['attribute_2'] * test['attribute_3']\n",
    "\n",
    "#train.head()\n",
    "\n",
    "# One-hot encoding\n",
    "encoded_col = []\n",
    "for col in encoded_col:\n",
    "     tmp_train= pd.get_dummies(test[col], prefix = col)\n",
    "     test = pd.merge(left = test, right = tmp_train, left_index = True, right_index = True)\n",
    "test = test.drop(encoded_col, axis = 1)\n",
    "#test.head()\n",
    "\n",
    "x_train = train[train.columns.difference([\"failure\",'id',\"attribute_2\",\"attribute_3\"])]\n",
    "x_test = test[test.columns.difference(['id', \"attribute_2\",\"attribute_3\"])]\n",
    "y_train = train[\"failure\"]\n",
    "\n",
    "iter_imputer = IterativeImputer(max_iter = 8, random_state = 0, skip_complete = True, n_nearest_features = 12)\n",
    "\n",
    "x_train = iter_imputer.fit_transform(x_train)\n",
    "x_test = iter_imputer.transform(x_test)\n",
    "#x_train.head()\n",
    "#x_test.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e1160c1",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2814d693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "665/665 [==============================] - 1s 1ms/step - loss: 1.9302 - accuracy: 0.6937 - val_loss: 0.7444 - val_accuracy: 0.5401\n",
      "Epoch 2/100\n",
      "665/665 [==============================] - 1s 839us/step - loss: 0.7367 - accuracy: 0.7145 - val_loss: 0.5456 - val_accuracy: 0.7911\n",
      "Epoch 3/100\n",
      "665/665 [==============================] - 1s 832us/step - loss: 0.6971 - accuracy: 0.7305 - val_loss: 0.6106 - val_accuracy: 0.7928\n",
      "Epoch 4/100\n",
      "665/665 [==============================] - 1s 812us/step - loss: 0.6373 - accuracy: 0.7353 - val_loss: 0.6991 - val_accuracy: 0.7928\n",
      "Epoch 5/100\n",
      "665/665 [==============================] - 1s 803us/step - loss: 0.6369 - accuracy: 0.7401 - val_loss: 0.9269 - val_accuracy: 0.3152\n",
      "Epoch 6/100\n",
      "665/665 [==============================] - 1s 819us/step - loss: 0.6103 - accuracy: 0.7476 - val_loss: 0.5056 - val_accuracy: 0.7932\n",
      "Epoch 7/100\n",
      "665/665 [==============================] - 1s 816us/step - loss: 0.5954 - accuracy: 0.7538 - val_loss: 0.5511 - val_accuracy: 0.7928\n",
      "Epoch 8/100\n",
      "665/665 [==============================] - 1s 809us/step - loss: 0.5767 - accuracy: 0.7653 - val_loss: 0.5080 - val_accuracy: 0.7889\n",
      "Epoch 9/100\n",
      "665/665 [==============================] - 1s 803us/step - loss: 0.5515 - accuracy: 0.7747 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
      "Epoch 10/100\n",
      "665/665 [==============================] - 1s 833us/step - loss: 0.5309 - accuracy: 0.7817 - val_loss: 0.5210 - val_accuracy: 0.7928\n",
      "Epoch 11/100\n",
      "665/665 [==============================] - 1s 810us/step - loss: 0.5227 - accuracy: 0.7849 - val_loss: 0.5061 - val_accuracy: 0.7928\n",
      "Epoch 12/100\n",
      "665/665 [==============================] - 1s 804us/step - loss: 0.5162 - accuracy: 0.7857 - val_loss: 0.5058 - val_accuracy: 0.7930\n",
      "Epoch 13/100\n",
      "665/665 [==============================] - 1s 825us/step - loss: 0.5179 - accuracy: 0.7851 - val_loss: 0.5036 - val_accuracy: 0.7930\n",
      "Epoch 14/100\n",
      "665/665 [==============================] - 1s 824us/step - loss: 0.5166 - accuracy: 0.7858 - val_loss: 0.5047 - val_accuracy: 0.7928\n",
      "Epoch 15/100\n",
      "665/665 [==============================] - 1s 823us/step - loss: 0.5171 - accuracy: 0.7856 - val_loss: 0.5068 - val_accuracy: 0.7928\n",
      "Epoch 16/100\n",
      "665/665 [==============================] - 1s 845us/step - loss: 0.5154 - accuracy: 0.7858 - val_loss: 0.5041 - val_accuracy: 0.7928\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - 1s 831us/step - loss: 0.5151 - accuracy: 0.7858 - val_loss: 0.5030 - val_accuracy: 0.7928\n",
      "Epoch 18/100\n",
      "665/665 [==============================] - 1s 802us/step - loss: 0.5161 - accuracy: 0.7861 - val_loss: 0.5068 - val_accuracy: 0.7928\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - 1s 791us/step - loss: 0.5171 - accuracy: 0.7859 - val_loss: 0.5043 - val_accuracy: 0.7928\n",
      "Epoch 20/100\n",
      "665/665 [==============================] - 1s 793us/step - loss: 0.5152 - accuracy: 0.7858 - val_loss: 0.5054 - val_accuracy: 0.7930\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - 1s 809us/step - loss: 0.5147 - accuracy: 0.7860 - val_loss: 0.5069 - val_accuracy: 0.7928\n",
      "Epoch 22/100\n",
      "665/665 [==============================] - 1s 785us/step - loss: 0.5161 - accuracy: 0.7860 - val_loss: 0.5058 - val_accuracy: 0.7930\n",
      "Epoch 23/100\n",
      "665/665 [==============================] - 1s 780us/step - loss: 0.5157 - accuracy: 0.7859 - val_loss: 0.5195 - val_accuracy: 0.7919\n",
      "Epoch 24/100\n",
      "665/665 [==============================] - 1s 773us/step - loss: 0.5163 - accuracy: 0.7858 - val_loss: 0.5832 - val_accuracy: 0.7928\n",
      "Epoch 25/100\n",
      "665/665 [==============================] - 1s 780us/step - loss: 0.5166 - accuracy: 0.7857 - val_loss: 0.5063 - val_accuracy: 0.7928\n",
      "Epoch 26/100\n",
      "665/665 [==============================] - 1s 774us/step - loss: 0.5151 - accuracy: 0.7856 - val_loss: 0.5039 - val_accuracy: 0.7930\n",
      "Epoch 27/100\n",
      "665/665 [==============================] - 1s 781us/step - loss: 0.5153 - accuracy: 0.7852 - val_loss: 0.5058 - val_accuracy: 0.7928\n",
      "Epoch 28/100\n",
      "665/665 [==============================] - 1s 861us/step - loss: 0.5151 - accuracy: 0.7857 - val_loss: 0.5038 - val_accuracy: 0.7930\n",
      "Epoch 29/100\n",
      "665/665 [==============================] - 1s 857us/step - loss: 0.5149 - accuracy: 0.7857 - val_loss: 0.5039 - val_accuracy: 0.7930\n",
      "Epoch 30/100\n",
      "665/665 [==============================] - 1s 812us/step - loss: 0.5152 - accuracy: 0.7856 - val_loss: 0.5121 - val_accuracy: 0.7926\n",
      "Epoch 31/100\n",
      "665/665 [==============================] - 1s 800us/step - loss: 0.5161 - accuracy: 0.7853 - val_loss: 0.5167 - val_accuracy: 0.7928\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - 1s 804us/step - loss: 0.5141 - accuracy: 0.7858 - val_loss: 0.5259 - val_accuracy: 0.7892\n",
      "Epoch 33/100\n",
      "665/665 [==============================] - 1s 806us/step - loss: 0.5135 - accuracy: 0.7857 - val_loss: 0.5093 - val_accuracy: 0.7934\n",
      "Epoch 34/100\n",
      "665/665 [==============================] - 1s 817us/step - loss: 0.5139 - accuracy: 0.7860 - val_loss: 0.5033 - val_accuracy: 0.7924\n",
      "Epoch 35/100\n",
      "665/665 [==============================] - 1s 861us/step - loss: 0.5143 - accuracy: 0.7858 - val_loss: 0.5169 - val_accuracy: 0.7928\n",
      "Epoch 36/100\n",
      "665/665 [==============================] - 1s 842us/step - loss: 0.5161 - accuracy: 0.7853 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
      "Epoch 37/100\n",
      "665/665 [==============================] - 1s 799us/step - loss: 0.5143 - accuracy: 0.7853 - val_loss: 0.5030 - val_accuracy: 0.7928\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7855 - val_loss: 0.5050 - val_accuracy: 0.7926\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5136 - accuracy: 0.7857 - val_loss: 0.5098 - val_accuracy: 0.7913\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7854 - val_loss: 0.5052 - val_accuracy: 0.7928\n",
      "Epoch 41/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5143 - accuracy: 0.7855 - val_loss: 0.5084 - val_accuracy: 0.7921\n",
      "Epoch 42/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7856 - val_loss: 0.5136 - val_accuracy: 0.7928\n",
      "Epoch 43/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7850 - val_loss: 0.5031 - val_accuracy: 0.7928\n",
      "Epoch 44/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7856 - val_loss: 0.5086 - val_accuracy: 0.7928\n",
      "Epoch 45/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.7861 - val_loss: 0.5067 - val_accuracy: 0.7915\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5162 - accuracy: 0.7858 - val_loss: 0.5045 - val_accuracy: 0.7930\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7848 - val_loss: 0.5066 - val_accuracy: 0.7922\n",
      "Epoch 48/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5131 - accuracy: 0.7857 - val_loss: 0.5048 - val_accuracy: 0.7924\n",
      "Epoch 49/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.7857 - val_loss: 0.5036 - val_accuracy: 0.7932\n",
      "Epoch 50/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5135 - accuracy: 0.7862 - val_loss: 0.5054 - val_accuracy: 0.7928\n",
      "Epoch 51/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5124 - accuracy: 0.7856 - val_loss: 0.5035 - val_accuracy: 0.7928\n",
      "Epoch 52/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5125 - accuracy: 0.7858 - val_loss: 0.5053 - val_accuracy: 0.7930\n",
      "Epoch 53/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5130 - accuracy: 0.7853 - val_loss: 0.5063 - val_accuracy: 0.7928\n",
      "Epoch 54/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7861 - val_loss: 0.5047 - val_accuracy: 0.7928\n",
      "Epoch 55/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5141 - accuracy: 0.7857 - val_loss: 0.5081 - val_accuracy: 0.7926\n",
      "Epoch 56/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7858 - val_loss: 0.5039 - val_accuracy: 0.7934\n",
      "Epoch 57/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5132 - accuracy: 0.7855 - val_loss: 0.5041 - val_accuracy: 0.7934\n",
      "Epoch 58/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5137 - accuracy: 0.7858 - val_loss: 0.5035 - val_accuracy: 0.7928\n",
      "Epoch 59/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7852 - val_loss: 0.5030 - val_accuracy: 0.7930\n",
      "Epoch 60/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7859 - val_loss: 0.5048 - val_accuracy: 0.7928\n",
      "Epoch 61/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.7855 - val_loss: 0.5084 - val_accuracy: 0.7928\n",
      "Epoch 62/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.7854 - val_loss: 0.5038 - val_accuracy: 0.7928\n",
      "Epoch 63/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7860 - val_loss: 0.5048 - val_accuracy: 0.7928\n",
      "Epoch 64/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5142 - accuracy: 0.7853 - val_loss: 0.5032 - val_accuracy: 0.7928\n",
      "Epoch 65/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5131 - accuracy: 0.7855 - val_loss: 0.5034 - val_accuracy: 0.7928\n",
      "Epoch 66/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5123 - accuracy: 0.7858 - val_loss: 0.5085 - val_accuracy: 0.7921\n",
      "Epoch 67/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7858 - val_loss: 0.5038 - val_accuracy: 0.7928\n",
      "Epoch 68/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.7856 - val_loss: 0.5077 - val_accuracy: 0.7930\n",
      "Epoch 69/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7856 - val_loss: 0.5053 - val_accuracy: 0.7930\n",
      "Epoch 70/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5117 - accuracy: 0.7854 - val_loss: 0.5029 - val_accuracy: 0.7930\n",
      "Epoch 71/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7858 - val_loss: 0.5072 - val_accuracy: 0.7928\n",
      "Epoch 72/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7856 - val_loss: 0.5088 - val_accuracy: 0.7928\n",
      "Epoch 73/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5131 - accuracy: 0.7856 - val_loss: 0.5032 - val_accuracy: 0.7928\n",
      "Epoch 74/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7853 - val_loss: 0.5032 - val_accuracy: 0.7930\n",
      "Epoch 75/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5135 - accuracy: 0.7861 - val_loss: 0.5023 - val_accuracy: 0.7930\n",
      "Epoch 76/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5131 - accuracy: 0.7858 - val_loss: 0.5078 - val_accuracy: 0.7921\n",
      "Epoch 77/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5123 - accuracy: 0.7854 - val_loss: 0.5039 - val_accuracy: 0.7930\n",
      "Epoch 78/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.7859 - val_loss: 0.5035 - val_accuracy: 0.7928\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5117 - accuracy: 0.7857 - val_loss: 0.5088 - val_accuracy: 0.7922\n",
      "Epoch 80/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.7853 - val_loss: 0.5071 - val_accuracy: 0.7928\n",
      "Epoch 81/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7855 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
      "Epoch 82/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7857 - val_loss: 0.5030 - val_accuracy: 0.7930\n",
      "Epoch 83/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5121 - accuracy: 0.7859 - val_loss: 0.5051 - val_accuracy: 0.7928\n",
      "Epoch 84/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7857 - val_loss: 0.5037 - val_accuracy: 0.7932\n",
      "Epoch 85/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7852 - val_loss: 0.5089 - val_accuracy: 0.7928\n",
      "Epoch 86/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7862 - val_loss: 0.5049 - val_accuracy: 0.7928\n",
      "Epoch 87/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5125 - accuracy: 0.7855 - val_loss: 0.5033 - val_accuracy: 0.7928\n",
      "Epoch 88/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5125 - accuracy: 0.7856 - val_loss: 0.5046 - val_accuracy: 0.7930\n",
      "Epoch 89/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5118 - accuracy: 0.7858 - val_loss: 0.5030 - val_accuracy: 0.7926\n",
      "Epoch 90/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7856 - val_loss: 0.5129 - val_accuracy: 0.7898\n",
      "Epoch 91/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7854 - val_loss: 0.5030 - val_accuracy: 0.7930\n",
      "Epoch 92/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7864 - val_loss: 0.5030 - val_accuracy: 0.7928\n",
      "Epoch 93/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5118 - accuracy: 0.7857 - val_loss: 0.5033 - val_accuracy: 0.7928\n",
      "Epoch 94/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5142 - accuracy: 0.7855 - val_loss: 0.5110 - val_accuracy: 0.7928\n",
      "Epoch 95/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.7856 - val_loss: 0.5031 - val_accuracy: 0.7928\n",
      "Epoch 96/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.7854 - val_loss: 0.5186 - val_accuracy: 0.7928\n",
      "Epoch 97/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5123 - accuracy: 0.7857 - val_loss: 0.5042 - val_accuracy: 0.7922\n",
      "Epoch 98/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.7860 - val_loss: 0.5035 - val_accuracy: 0.7928\n",
      "Epoch 99/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.7861 - val_loss: 0.5059 - val_accuracy: 0.7926\n",
      "Epoch 100/100\n",
      "665/665 [==============================] - 1s 2ms/step - loss: 0.5120 - accuracy: 0.7858 - val_loss: 0.5033 - val_accuracy: 0.7928\n"
     ]
    }
   ],
   "source": [
    "number_of_features = x_train.shape[1]\n",
    "model = tf.keras.models.Sequential([\n",
    "    Dense(6,input_dim = number_of_features),\n",
    "    LeakyReLU(alpha=0.06)\n",
    "])\n",
    "\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-2,decay_steps=10000,decay_rate=0.9)#1e-2,0.9\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.add(tf.keras.layers.Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy',  metrics = ['accuracy'])#categorical_crossentropy\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_split = 0.2)# 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f075bb8",
   "metadata": {},
   "source": [
    "# Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ace330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('109550135_model.h5') # In the same directory as this file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "da82e2444a858c0e6f7823633dc56ff3b236dbe57b9476fd66c4ad2e5bdc4c81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
